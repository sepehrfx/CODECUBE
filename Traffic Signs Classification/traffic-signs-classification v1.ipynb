{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:blue; border-radius:2px; border:#000000 solid; padding: 15px; font-size:100%; text-align:center\">\n",
    "    <h1 align=\"center\" style=\"color:#ffffff;\"><b>Traffic Sign Recognition üö¶üîç</b></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000000; border-radius:2px; border:#000000 solid; padding: 15px; font-size:100%; text-align:center\">\n",
    "    <img src=\"https://media.tenor.com/NxZUCukvV5MAAAAd/traffic-cars.gif\" alt=\"Animated GIF\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:blue; border-radius:2px; border:#000000 solid; padding: 15px; font-size:100%; text-align:center\">\n",
    "    <h2 align=\"center\" style=\"color:#ffffff;\"><b>IMPORT DEPENDENCIES</b></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T08:41:16.443166Z",
     "iopub.status.busy": "2023-11-30T08:41:16.442345Z",
     "iopub.status.idle": "2023-11-30T08:41:34.582605Z",
     "shell.execute_reply": "2023-11-30T08:41:34.581494Z",
     "shell.execute_reply.started": "2023-11-30T08:41:16.443113Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas opencv-python matplotlib seaborn tensorflow keras pillow plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-30T08:46:45.024737Z",
     "iopub.status.busy": "2023-11-30T08:46:45.024013Z",
     "iopub.status.idle": "2023-11-30T08:46:45.029958Z",
     "shell.execute_reply": "2023-11-30T08:46:45.029262Z",
     "shell.execute_reply.started": "2023-11-30T08:46:45.024703Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import style\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T08:46:47.901038Z",
     "iopub.status.busy": "2023-11-30T08:46:47.900687Z",
     "iopub.status.idle": "2023-11-30T08:46:47.907353Z",
     "shell.execute_reply": "2023-11-30T08:46:47.906723Z",
     "shell.execute_reply.started": "2023-11-30T08:46:47.901005Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_images(directory_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "    subdirectories = [subdir for subdir in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, subdir))]\n",
    "\n",
    "    for subdir in subdirectories:\n",
    "        subdirectory_path = os.path.join(directory_path, subdir)\n",
    "        if not os.listdir(subdirectory_path):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(subdirectory_path):\n",
    "            if filename.lower().endswith(valid_extensions):\n",
    "                image_path = os.path.join(subdirectory_path, filename)\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, (30, 30))\n",
    "                images.append(image)\n",
    "\n",
    "                label = int(subdir)\n",
    "                labels.append(label)\n",
    "\n",
    "    data = np.array(list(zip(images, labels)))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:blue; border-radius:2px; border:#000000 solid; padding: 15px; font-size:100%; text-align:center\">\n",
    "    <h2 align=\"center\" style=\"color:#ffffff;\"><b>DATA PREPARETION</b></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T08:42:04.149364Z",
     "iopub.status.busy": "2023-11-30T08:42:04.148962Z",
     "iopub.status.idle": "2023-11-30T08:44:44.447252Z",
     "shell.execute_reply": "2023-11-30T08:44:44.446431Z",
     "shell.execute_reply.started": "2023-11-30T08:42:04.149328Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (39209, 2) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/gtsrb-german-traffic-sign/Train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mread_images\u001b[0;34m(directory_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m             label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(subdir)\n\u001b[1;32m     22\u001b[0m             labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m---> 24\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (39209, 2) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "train_data = read_images('/kaggle/input/gtsrb-german-traffic-sign/Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Data Shape : {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Overview\n",
    "classes = { \n",
    "    0:'Speed limit (20km/h)',\n",
    "    1:'Speed limit (30km/h)', \n",
    "    2:'Speed limit (50km/h)', \n",
    "    3:'Speed limit (60km/h)', \n",
    "    4:'Speed limit (70km/h)', \n",
    "    5:'Speed limit (80km/h)', \n",
    "    6:'End of speed limit (80km/h)', \n",
    "    7:'Speed limit (100km/h)', \n",
    "    8:'Speed limit (120km/h)', \n",
    "    9:'No passing', \n",
    "    10:'No passing veh over 3.5 tons', \n",
    "    11:'Right-of-way at intersection', \n",
    "    12:'Priority road', \n",
    "    13:'Yield', \n",
    "    14:'Stop', \n",
    "    15:'No vehicles', \n",
    "    16:'Veh > 3.5 tons prohibited', \n",
    "    17:'No entry', \n",
    "    18:'General caution', \n",
    "    19:'Dangerous curve left', \n",
    "    20:'Dangerous curve right', \n",
    "    21:'Double curve', \n",
    "    22:'Bumpy road', \n",
    "    23:'Slippery road', \n",
    "    24:'Road narrows on the right', \n",
    "    25:'Road work', \n",
    "    26:'Traffic signals', \n",
    "    27:'Pedestrians', \n",
    "    28:'Children crossing', \n",
    "    29:'Bicycles crossing', \n",
    "    30:'Beware of ice/snow',\n",
    "    31:'Wild animals crossing', \n",
    "    32:'End speed + passing limits', \n",
    "    33:'Turn right ahead', \n",
    "    34:'Turn left ahead', \n",
    "    35:'Ahead only', \n",
    "    36:'Go straight or right', \n",
    "    37:'Go straight or left', \n",
    "    38:'Keep right', \n",
    "    39:'Keep left', \n",
    "    40:'Roundabout mandatory', \n",
    "    41:'End of no passing', \n",
    "    42:'End no passing veh > 3.5 tons'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_data[:, 1].astype(int)  # Extract the labels from the train_data array\n",
    "unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "count_dict= {label: count for label, count in zip(unique_labels, label_counts)}\n",
    "print(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_color = '#8A2BE2'\n",
    "\n",
    "color_scale = [[0, base_color], [1, 'rgb(30,30,30)']]\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(\n",
    "    x=label_counts,\n",
    "    y=[classes[label] for label in unique_labels],\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color=label_counts,\n",
    "        coloraxis='coloraxis'\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Label Counts in Train Data',\n",
    "    xaxis_title='Count',\n",
    "    yaxis_title='Label',\n",
    "    plot_bgcolor='rgb(30,30,30)',\n",
    "    paper_bgcolor='rgb(30,30,30)',\n",
    "    font=dict(color='white'),\n",
    "    coloraxis=dict(colorscale=color_scale)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_color = '#8A2BE2'\n",
    "color_palette = sns.color_palette(\"husl\", len(count_dict)).as_hex()\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=list(count_dict.keys()),\n",
    "    values=list(count_dict.values()),\n",
    "    marker=dict(colors=color_palette),\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Label Distribution',\n",
    "    font=dict(color='white'),\n",
    "    paper_bgcolor='rgb(30,30,30)',\n",
    "    plot_bgcolor='rgb(30,30,30)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(train_data.shape[0], size=10, replace=False)\n",
    "samples = train_data[indices]\n",
    "\n",
    "fig = make_subplots(rows=2, cols=5, subplot_titles=[classes[label] for _, label in samples])\n",
    "\n",
    "for i, (image, label) in enumerate(samples):\n",
    "    row = i // 5 + 1\n",
    "    col = i % 5 + 1\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Image(z=image),\n",
    "        row=row,\n",
    "        col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Random Samples',\n",
    "    font=dict(color='white'),\n",
    "    paper_bgcolor='rgb(30,30,30)',\n",
    "    plot_bgcolor='rgb(30,30,30)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.DataFrame(train_data, columns=['Image', 'Label'])\n",
    "train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the desired number of samples to select from each class\n",
    "class_count = 200  \n",
    "\n",
    "# Group the DataFrame by the 'Label' column\n",
    "grouped = train_.groupby('Label')\n",
    "\n",
    "# Use the apply function to randomly select the specified number of samples from each class\n",
    "balanced_df = grouped.apply(lambda x: x.sample(class_count))\n",
    "\n",
    "# Reset the index of the balanced DataFrame to maintain a clean structure\n",
    "balanced_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced = balanced_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = train_balanced[:, 1].astype(int)  # Extract the labels from the train_data array\n",
    "new_unique_labels, new_label_counts = np.unique(new_labels, return_counts=True)\n",
    "new_count_dict= {label: count for label, count in zip(new_unique_labels, new_label_counts)}\n",
    "print(new_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_color = '#8A2BE2'\n",
    "color_palette = sns.color_palette(\"husl\", len(new_count_dict)).as_hex()\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=list(new_count_dict.keys()),\n",
    "    values=list(new_count_dict.values()),\n",
    "    marker=dict(colors=color_palette),\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Label Distribution',\n",
    "    font=dict(color='white'),\n",
    "    paper_bgcolor='rgb(30,30,30)',\n",
    "    plot_bgcolor='rgb(30,30,30)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train = train_balanced.copy()     # Create a copy of train_data to avoid modifying the original array\n",
    "shuffled_train = np.array(shuffled_train)  # Shuffle the array randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the shuffled_train array into training and testing sets\n",
    "train_set, test_set = train_test_split(shuffled_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate the input (X) and output/label (y) arrays from the training set\n",
    "x_train, y_train = train_set[:, 0], train_set[:, 1]\n",
    "\n",
    "# Separate the input (X) and output/label (y) arrays from the testing set\n",
    "x_test, y_test = test_set[:, 0], test_set[:, 1]\n",
    "\n",
    "# Convert the data type of the arrays to int\n",
    "x_train, y_train, x_test, y_test = map(np.array, [x_train, y_train, x_test, y_test])\n",
    "\n",
    "# Normalize the input data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Display the shapes of the arrays\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test  shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test  shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=43)\n",
    "y_test  = to_categorical(y_test, num_classes=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:blue; border-radius:2px; border:#000000 solid; padding: 15px; font-size:100%; text-align:center\">\n",
    "    <h2 align=\"center\" style=\"color:#ffffff;\"><b>MODEL ENGINEERING</b></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(30,30,3)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 30\n",
    "opt = Adam(learning_rate=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"reflect\"\n",
    ")\n",
    "\n",
    "history = model.fit(aug.flow(x_train, y_train, batch_size=32), epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, epochs+1)),\n",
    "    y=history.history['loss'],\n",
    "    mode='lines',\n",
    "    name='Training Loss'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, epochs+1)),\n",
    "    y=history.history['val_loss'],\n",
    "    mode='lines',\n",
    "    name='Validation Loss'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Loss',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Loss',\n",
    "    font=dict(color='white'),\n",
    "    paper_bgcolor='rgb(30,30,30)',\n",
    "    plot_bgcolor='rgb(30,30,30)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, epochs+1)),\n",
    "    y=history.history['accuracy'],\n",
    "    mode='lines',\n",
    "    name='Training Accuracy'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, epochs+1)),\n",
    "    y=history.history['val_accuracy'],\n",
    "    mode='lines',\n",
    "    name='Validation Accuracy'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Accuracy',\n",
    "    xaxis_title='Epochs',\n",
    "    yaxis_title='Accuracy',\n",
    "    font=dict(color='white'),\n",
    "    paper_bgcolor='rgb(30,30,30)',\n",
    "    plot_bgcolor='rgb(30,30,30)'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "shuffled_train_dataframe = pd.DataFrame(shuffled_train)\n",
    "# Save DataFrame as CSV file\n",
    "shuffled_train_dataframe.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model_path, image_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (30, 30))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    predictions = model.predict(image)\n",
    "    predicted_label = np.argmax(predictions)\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "model_path = \"/kaggle/working/saved_model.h5\"\n",
    "image_path = \"/kaggle/input/gtsrb-german-traffic-sign/Test/00080.png\"\n",
    "predicted_label = predict_image(model_path, image_path)\n",
    "print(\"Predicted Label:\", classes[predicted_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Let's practice object-oriented programming (OOP) with TensorFlow :) \n",
    "\"\"\"\n",
    "class TrafficSignModel:\n",
    "    def __init__(self):\n",
    "        self.model = self.build_model()\n",
    "        self.lr = 0.001\n",
    "        self.epochs = 30\n",
    "        self.opt = Adam(learning_rate=self.lr)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=self.opt, metrics=['accuracy'])\n",
    "\n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(30,30,3)),\n",
    "            Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "            MaxPool2D(pool_size=(2, 2)),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "            Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "            MaxPool2D(pool_size=(2, 2)),\n",
    "            BatchNormalization(axis=-1),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(rate=0.5),\n",
    "            Dense(43, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def train_model(self, x_train, y_train, x_test, y_test):\n",
    "        aug = ImageDataGenerator(\n",
    "            rotation_range=15,\n",
    "            zoom_range=0.2,\n",
    "            width_shift_range=0.15,\n",
    "            height_shift_range=0.15,\n",
    "            shear_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            fill_mode=\"reflect\"\n",
    "        )\n",
    "        history = self.model.fit(aug.flow(x_train, y_train, batch_size=32), epochs=self.epochs, validation_data=(x_test, y_test))\n",
    "        return history\n",
    "\n",
    "    def plot_loss(self, history):\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=list(range(1, self.epochs+1)), y=history.history['loss'], mode='lines', name='Training Loss'))\n",
    "        fig.add_trace(go.Scatter(x=list(range(1, self.epochs+1)), y=history.history['val_loss'], mode='lines', name='Validation Loss'))\n",
    "        self.update_plot_layout(fig)\n",
    "        fig.show()\n",
    "\n",
    "    def plot_accuracy(self, history):\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=list(range(1, self.epochs+1)), y=history.history['accuracy'], mode='lines', name='Training Accuracy'))\n",
    "        fig.add_trace(go.Scatter(x=list(range(1, self.epochs+1)), y=history.history['val_accuracy'], mode='lines', name='Validation Accuracy'))\n",
    "        self.update_plot_layout(fig)\n",
    "        fig.show()\n",
    "\n",
    "    def update_plot_layout(self, fig):\n",
    "        fig.update_layout(\n",
    "            title='Model Loss/Accuracy',\n",
    "            xaxis_title='Epochs',\n",
    "            font=dict(color='white'),\n",
    "            paper_bgcolor='rgb(30,30,30)',\n",
    "            plot_bgcolor='rgb(30,30,30)'\n",
    "        )\n",
    "\n",
    "    def save_dataframe_to_csv(self, data, filename='data.csv'):\n",
    "        shuffled_train_dataframe = pd.DataFrame(data)\n",
    "        shuffled_train_dataframe.to_csv(filename, index=False)\n",
    "\n",
    "    def save_model(self, filename='saved_model.h5'):\n",
    "        self.model.save(filename)\n",
    "\n",
    "    def predict_image(self, model_path, image_path):\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (30, 30))\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image / 255.0\n",
    "        predictions = model.predict(image)\n",
    "        predicted_label = np.argmax(predictions)\n",
    "        return predicted_label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample usage\n",
    "    traffic_sign_model = TrafficSignModel()\n",
    "    # Train the model with your actual data\n",
    "    history = traffic_sign_model.train_model(x_train, y_train, x_test, y_test)\n",
    "    # Plot loss and accuracy\n",
    "    traffic_sign_model.plot_loss(history)\n",
    "    traffic_sign_model.plot_accuracy(history)\n",
    "    # Save data to CSV and model to h5\n",
    "    traffic_sign_model.save_dataframe_to_csv(shuffled_train)\n",
    "    traffic_sign_model.save_model()\n",
    "    # Predict image label\n",
    "    model_path = \"saved_model.h5\"\n",
    "    image_path = \"input/gtsrb-german-traffic-sign/Test/00080.png\"\n",
    "    predicted_label = traffic_sign_model.predict_image(model_path, image_path)\n",
    "    print(\"Predicted Label:\", classes[predicted_label])\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 82373,
     "sourceId": 191501,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
